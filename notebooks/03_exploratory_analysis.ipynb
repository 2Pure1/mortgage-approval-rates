{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà NOTEBOOK 3: EXPLORATORY DATA ANALYSIS & HMDA INTEGRATION\n",
    "## Mortgage Approval Rate Forecasting Project | Business Insight Generation\n",
    "\n",
    "### üéØ BUSINESS OBJECTIVE\n",
    "**Primary Goal**: Discover and validate the economic relationships that drive mortgage approval decisions through comprehensive exploratory analysis and HMDA data integration.\n",
    "\n",
    "**Business Impact**: Enable stakeholders to:\n",
    "- Understand which economic factors most influence approval rates\n",
    "- Validate expected economic relationships with empirical evidence\n",
    "- Build confidence in the modeling approach through transparent analysis\n",
    "- Identify key drivers for strategic business decisions\n",
    "\n",
    "### üìä STRATEGIC CONTEXT: EXPLORATORY ANALYSIS PHILOSOPHY\n",
    "**Critical Insight**: Effective mortgage forecasting requires understanding not just statistical relationships, but the economic logic behind lending decisions.\n",
    "\n",
    "**Analytical Framework**:\n",
    "- **Economic Theory Validation**: Test established economic relationships in mortgage lending\n",
    "- **Data-Driven Discovery**: Uncover unexpected patterns and interactions\n",
    "- **Business Context Integration**: Connect statistical findings to real-world lending practices\n",
    "- **Modeling Readiness Assessment**: Ensure data quality for predictive modeling\n",
    "\n",
    "### üîç ANALYTICAL APPROACH\n",
    "We'll conduct comprehensive exploratory analysis to validate economic relationships, integrate HMDA data, and prepare the final modeling dataset with full business context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 1: INITIALIZATION & STRATEGIC FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ THINKING PROCESS: EXPLORATORY ANALYSIS STRATEGY\n",
    "\n",
    "**Business Rationale for EDA**:\n",
    "- **Risk Mitigation**: Identify data issues before modeling to prevent unreliable predictions\n",
    "- **Relationship Validation**: Confirm expected economic relationships exist in the data\n",
    "- **Feature Selection**: Identify the most promising predictors for mortgage approvals\n",
    "- **Stakeholder Confidence**: Transparent analysis builds trust in subsequent modeling\n",
    "\n",
    "**Strategic Analysis Principles**:\n",
    "1. **Hypothesis-Driven Exploration**: Test specific economic theories about mortgage lending\n",
    "2. **Multi-Perspective Analysis**: Examine relationships from different angles (correlation, visualization, business logic)\n",
    "3. **Economic Context Integration**: Interpret findings within the 2018-2024 economic landscape\n",
    "4. **Actionable Insights Focus**: Generate findings that directly inform business decisions\n",
    "\n",
    "**Key Economic Hypotheses to Test**:\n",
    "- Higher unemployment ‚Üí Lower approval rates (risk aversion)\n",
    "- Strong GDP growth ‚Üí Higher approval rates (economic confidence)\n",
    "- Rising home prices ‚Üí Higher approval rates (collateral value)\n",
    "- Higher mortgage rates ‚Üí Lower approval rates (affordability constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß COMPREHENSIVE ANALYTICAL ENVIRONMENT SETUP\n",
    "# Thinking: Robust toolkit for multi-faceted exploratory analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Professional visualization styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"‚úÖ EXPLORATORY ANALYSIS ENVIRONMENT INITIALIZED\")\n",
    "print(\"üìä Available Tools: Statistical testing, advanced visualization, correlation analysis\")\n",
    "print(\"üéØ Business Focus: Economic relationship validation and insight generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 2: ENGINEERED FEATURES LOADING & VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ THINKING PROCESS: DATA QUALITY ASSURANCE\n",
    "\n",
    "**Strategic Validation Framework**:\n",
    "\n",
    "| Validation Dimension | Assessment Method | Business Impact |\n",
    "|---------------------|-------------------|------------------|\n",
    "| **Feature Integrity** | Missing values, data types | Model reliability |\n",
    "| **Temporal Coverage** | Date range verification | Historical context |\n",
    "| **Economic Plausibility** | Value range checks | Realistic scenarios |\n",
    "| **Feature Diversity** | Correlation analysis | Predictive power |\n",
    "\n",
    "**Critical Success Factors**:\n",
    "- All engineered features from Notebook 2 properly loaded\n",
    "- No data degradation during persistence/loading\n",
    "- Features maintain economic meaning and relationships\n",
    "- Ready for integration with HMDA approval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ STRATEGIC DATA LOADING WITH COMPREHENSIVE VALIDATION\n",
    "# Thinking: Ensure data integrity before extensive analysis\n",
    "\n",
    "class DataIntegrityValidator:\n",
    "    \"\"\"\n",
    "    COMPREHENSIVE DATA INTEGRITY VALIDATION ENGINE\n",
    "    \n",
    "    Business Purpose: Verify that engineered features maintain\n",
    "    quality and integrity from Notebook 2 and are ready for\n",
    "    exploratory analysis and HMDA integration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.validation_results = {}\n",
    "    \n",
    "    def load_and_validate_features(self, file_path):\n",
    "        \"\"\"\n",
    "        ROBUST FEATURE LOADING WITH MULTI-LAYER VALIDATION\n",
    "        \n",
    "        Thinking: Catch any data integrity issues early to\n",
    "        prevent propagation through exploratory analysis.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"üìÇ LOADING ENGINEERED ECONOMIC FEATURES...\")\n",
    "        \n",
    "        try:\n",
    "            # Load the engineered features from Notebook 2\n",
    "            features = pd.read_parquet(file_path)\n",
    "            \n",
    "            # üßê COMPREHENSIVE INTEGRITY VALIDATION\n",
    "            integrity_checks = {\n",
    "                'successful_load': not features.empty,\n",
    "                'adequate_features': len(features.columns) >= 30,\n",
    "                'sufficient_quarters': len(features) >= 20,\n",
    "                'no_missing_values': features.isna().sum().sum() == 0,\n",
    "                'proper_index': isinstance(features.index, pd.DatetimeIndex),\n",
    "                'expected_date_range': features.index.min() <= pd.Timestamp('2018-01-01') and features.index.max() >= pd.Timestamp('2023-12-31')\n",
    "            }\n",
    "            \n",
    "            # üö® CRITICAL VALIDATION FAILURES\n",
    "            failed_checks = [check for check, passed in integrity_checks.items() if not passed]\n",
    "            if failed_checks:\n",
    "                raise ValueError(f\"Critical integrity failures: {failed_checks}\")\n",
    "            \n",
    "            print(f\"‚úÖ SUCCESS: Loaded {len(features)} quarters, {len(features.columns)} engineered features\")\n",
    "            \n",
    "            # üìä COMPREHENSIVE FEATURE INVENTORY\n",
    "            feature_inventory = self.analyze_feature_categories(features)\n",
    "            \n",
    "            return features, feature_inventory, integrity_checks\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå CRITICAL: Features file not found at {file_path}\")\n",
    "            print(\"üí° SOLUTION: Run Notebook 2 first to create engineered features\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Feature loading failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def analyze_feature_categories(self, features):\n",
    "        \"\"\"Comprehensive analysis of feature types and categories\"\"\"\n",
    "        \n",
    "        feature_categories = {\n",
    "            'original_aggregates': len([col for col in features.columns if '_Avg' in col or '_EOP' in col]),\n",
    "            'trend_features': len([col for col in features.columns if 'Change' in col or 'Momentum' in col]),\n",
    "            'comparative_features': len([col for col in features.columns if 'Deviation' in col or 'Percentile' in col]),\n",
    "            'interaction_features': len([col for col in features.columns if 'Interaction' in col or 'Spread' in col]),\n",
    "            'composite_indicators': len([col for col in features.columns if 'Strength' in col or 'Health' in col or 'Index' in col]),\n",
    "            'lagged_features': len([col for col in features.columns if 'Lag' in col])\n",
    "        }\n",
    "        \n",
    "        # Key economic indicator presence check\n",
    "        key_indicators = [\n",
    "            'Unemployment_Rate_EOP', 'GDP_Avg', 'Case_Shiller_Home_Price_Index_EOP',\n",
    "            '30Y_Fixed_Mortgage_Rate_EOP', 'Real_Disposable_Income_EOP'\n",
    "        ]\n",
    "        \n",
    "        available_indicators = [indicator for indicator in key_indicators if indicator in features.columns]\n",
    "        \n",
    "        inventory = {\n",
    "            'feature_categories': feature_categories,\n",
    "            'key_indicators_present': len(available_indicators),\n",
    "            'total_features': len(features.columns),\n",
    "            'date_range': f\"{features.index.min().strftime('%Y-Q%q')} to {features.index.max().strftime('%Y-Q%q')}\",\n",
    "            'memory_usage_mb': features.memory_usage(deep=True).sum() / 1024 / 1024\n",
    "        }\n",
    "        \n",
    "        return inventory\n",
    "\n",
    "# Initialize and execute feature loading with validation\n",
    "print(\"üîç INITIATING COMPREHENSIVE FEATURE INTEGRITY VALIDATION\")\n",
    "validator = DataIntegrityValidator()\n",
    "economic_features, feature_inventory, integrity_checks = validator.load_and_validate_features('../data/modeling_ready/engineered_economic_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 3: COMPREHENSIVE FEATURE INVENTORY REPORTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ THINKING PROCESS: FEATURE LANDSCAPE ASSESSMENT\n",
    "\n",
    "**Strategic Feature Evaluation**:\n",
    "- **Feature Diversity**: Multiple perspectives on economic conditions\n",
    "- **Economic Coverage**: All major economic categories represented\n",
    "- **Temporal Dynamics**: Lagged features capturing delayed effects\n",
    "- **Business Relevance**: Features aligned with lending decision factors\n",
    "\n",
    "**Business Impact Assessment**:\n",
    "- **Comprehensive Coverage**: Confidence that all relevant economic factors are captured\n",
    "- **Feature Quality**: Assurance that features are well-engineered and meaningful\n",
    "- **Modeling Potential**: Readiness for predictive modeling based on feature richness\n",
    "- **Interpretability Foundation**: Features that can be explained to business stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä EXECUTIVE FEATURE INVENTORY DASHBOARD\n",
    "# Thinking: Professional reporting of feature landscape for stakeholders\n",
    "\n",
    "def generate_feature_inventory_dashboard(feature_inventory, economic_features):\n",
    "    \"\"\"\n",
    "    PROFESSIONAL FEATURE INVENTORY FOR BUSINESS STAKEHOLDERS\n",
    "    \n",
    "    Business Purpose: Transparent communication of the feature\n",
    "    engineering results to build confidence in the modeling foundation.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä ENGINEERED FEATURE INVENTORY DASHBOARD\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # üéØ OVERALL FEATURE LANDSCAPE\n",
    "    print(f\"\\nüìà OVERALL FEATURE LANDSCAPE:\")\n",
    "    print(f\"   ‚Ä¢ Total Engineered Features: {feature_inventory['total_features']}\")\n",
    "    print(f\"   ‚Ä¢ Time Coverage: {feature_inventory['date_range']}\")\n",
    "    print(f\"   ‚Ä¢ Key Economic Indicators: {feature_inventory['key_indicators_present']}/5 present\")\n",
    "    print(f\"   ‚Ä¢ Memory Usage: {feature_inventory['memory_usage_mb']:.1f} MB\")\n",
    "    \n",
    "    # üìã FEATURE CATEGORY BREAKDOWN\n",
    "    print(f\"\\nüîß FEATURE CATEGORY BREAKDOWN:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    categories = feature_inventory['feature_categories']\n",
    "    for category, count in categories.items():\n",
    "        category_name = category.replace('_', ' ').title()\n",
    "        percentage = (count / feature_inventory['total_features']) * 100\n",
    "        print(f\"   ‚Ä¢ {category_name:25} : {count:3} features ({percentage:.1f}%)\")\n",
    "    \n",
    "    # üèÜ KEY ECONOMIC INDICATORS STATUS\n",
    "    print(f\"\\nüéØ KEY ECONOMIC INDICATORS STATUS:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    key_indicators = [\n",
    "        ('Unemployment_Rate_EOP', 'Labor Market Health'),\n",
    "        ('GDP_Avg', 'Economic Growth'),\n",
    "        ('Case_Shiller_Home_Price_Index_EOP', 'Housing Market'),\n",
    "        ('30Y_Fixed_Mortgage_Rate_EOP', 'Interest Rates'),\n",
    "        ('Real_Disposable_Income_EOP', 'Consumer Capacity')\n",
    "    ]\n",
    "    \n",
    "    for indicator, description in key_indicators:\n",
    "        status = \"‚úÖ PRESENT\" if indicator in economic_features.columns else \"‚ùå MISSING\"\n",
    "        print(f\"   ‚Ä¢ {description:20} : {status}\")\n",
    "    \n",
    "    # üìà FEATURE QUALITY ASSESSMENT\n",
    "    print(f\"\\nüîç FEATURE QUALITY ASSESSMENT:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Calculate feature quality metrics\n",
    "    quality_metrics = {\n",
    "        'features_with_variance': (economic_features.std() > 0).sum(),\n",
    "        'high_correlation_pairs': count_high_correlations(economic_features),\n",
    "        'features_in_reasonable_range': check_value_ranges(economic_features),\n",
    "        'missing_values_remaining': economic_features.isna().sum().sum()\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Features with Variance     : {quality_metrics['features_with_variance']}/{feature_inventory['total_features']}\")\n",
    "    print(f\"   ‚Ä¢ High Correlation Pairs     : {quality_metrics['high_correlation_pairs']}\")\n",
    "    print(f\"   ‚Ä¢ Features in Reasonable Range: {quality_metrics['features_in_reasonable_range']}/{feature_inventory['total_features']}\")\n",
    "    print(f\"   ‚Ä¢ Missing Values Remaining   : {quality_metrics['missing_values_remaining']}\")\n",
    "    \n",
    "    return quality_metrics\n",
    "\n",
    "def count_high_correlations(features, threshold=0.95):\n",
    "    \"\"\"Count feature pairs with very high correlation\"\"\"\n",
    "    corr_matrix = features.corr().abs()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    high_corr_pairs = (upper_triangle > threshold).sum().sum()\n",
    "    return high_corr_pairs\n",
    "\n",
    "def check_value_ranges(features):\n",
    "    \"\"\"Check if features have reasonable economic value ranges\"\"\"\n",
    "    reasonable_count = 0\n",
    "    for col in features.columns:\n",
    "        col_range = features[col].max() - features[col].min()\n",
    "        # Simple heuristic: features should have some meaningful variation\n",
    "        if col_range > 0.01:  # At least 1% variation\n",
    "            reasonable_count += 1\n",
    "    return reasonable_count\n",
    "\n",
    "# Generate comprehensive feature inventory\n",
    "quality_metrics = generate_feature_inventory_dashboard(feature_inventory, economic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 4: HMDA MORTGAGE APPROVAL DATA INTEGRATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ THINKING PROCESS: HMDA DATA STRATEGY\n",
    "\n",
    "**Business Context**: Real HMDA data requires special access and processing. We'll create a realistic simulation that captures:\n",
    "- **Approval Rate Dynamics**: Realistic ranges and patterns (60-80% typically)\n",
    "- **Economic Sensitivity**: Response to key economic indicators\n",
    "- **Temporal Patterns**: Seasonality and trend components\n",
    "- **COVID Impact**: Realistic disruption and recovery patterns\n",
    "\n",
    "**Strategic Simulation Principles**:\n",
    "1. **Economic Logic Foundation**: Approval rates driven by established economic relationships\n",
    "2. **Realistic Ranges**: Approval rates within historically observed bounds\n",
    "3. **Temporal Consistency**: Smooth transitions and realistic volatility\n",
    "4. **Business Plausibility**: Patterns that make sense to mortgage professionals\n",
    "\n",
    "**Key Economic Drivers in Simulation**:\n",
    "- Unemployment (strong negative impact)\n",
    "- Home price growth (strong positive impact) \n",
    "- GDP growth (moderate positive impact)\n",
    "- Mortgage rates (moderate negative impact)\n",
    "- Income growth (moderate positive impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè¶ REALISTIC HMDA APPROVAL DATA SIMULATION\n",
    "# Thinking: Create business-plausible mortgage approval data for analysis\n",
    "\n",
    "class HMDASimulator:\n",
    "    \"\"\"\n",
    "    REALISTIC HMDA MORTGAGE APPROVAL DATA SIMULATION\n",
    "    \n",
    "    Business Purpose: Create realistic mortgage approval rate data\n",
    "    that responds to economic conditions in a business-plausible way,\n",
    "    enabling meaningful exploratory analysis and modeling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.simulation_parameters = {\n",
    "            'base_approval_rate': 72.0,  # Long-term average around 72%\n",
    "            'economic_impact_weights': {\n",
    "                'unemployment': -2.5,    # Strong negative impact\n",
    "                'gdp_growth': 1.8,       # Moderate positive impact\n",
    "                'home_price_growth': 2.2, # Strong positive impact\n",
    "                'mortgage_rates': -1.5,  # Moderate negative impact\n",
    "                'income_growth': 1.2     # Moderate positive impact\n",
    "            },\n",
    "            'volatility': 1.8,           # Quarter-to-quarter variability\n",
    "            'seasonality_amplitude': 0.8, # Seasonal patterns\n",
    "            'covid_impact': -8.0         # COVID period impact\n",
    "        }\n",
    "    \n",
    "    def simulate_hmda_approval_rates(self, economic_features):\n",
    "        \"\"\"\n",
    "        BUSINESS-PLAUSIBLE APPROVAL RATE SIMULATION\n",
    "        \n",
    "        Thinking: Create approval rates that respond realistically\n",
    "        to economic conditions based on established lending practices\n",
    "        and historical patterns.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\nüè¶ SIMULATING HMDA MORTGAGE APPROVAL RATES...\")\n",
    "        \n",
    "        np.random.seed(42)  # For reproducible simulation\n",
    "        \n",
    "        approval_rates = []\n",
    "        dates = economic_features.index\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            # Base approval rate with seasonal component\n",
    "            base_rate = self.simulation_parameters['base_approval_rate']\n",
    "            \n",
    "            # üéØ ECONOMIC IMPACT CALCULATION\n",
    "            economic_impact = 0\n",
    "            \n",
    "            # Unemployment impact (using lagged values as lenders react to recent data)\n",
    "            if 'Unemployment_Rate_EOP_Lag_1Q' in economic_features.columns:\n",
    "                unemployment_effect = self.simulation_parameters['economic_impact_weights']['unemployment'] * \\\n",
    "                                   economic_features['Unemployment_Rate_EOP_Lag_1Q'].iloc[i]\n",
    "                economic_impact += unemployment_effect\n",
    "            \n",
    "            # GDP growth impact\n",
    "            if 'GDP_Avg_Lag_1Q' in economic_features.columns:\n",
    "                gdp_effect = self.simulation_parameters['economic_impact_weights']['gdp_growth'] * \\\n",
    "                           economic_features['GDP_Avg_Lag_1Q'].iloc[i]\n",
    "                economic_impact += gdp_effect\n",
    "            \n",
    "            # Home price growth impact\n",
    "            hpi_col = 'Case_Shiller_Home_Price_Index_EOP_Annual_Growth_Lag_1Q'\n",
    "            if hpi_col in economic_features.columns:\n",
    "                hpi_effect = self.simulation_parameters['economic_impact_weights']['home_price_growth'] * \\\n",
    "                           economic_features[hpi_col].iloc[i]\n",
    "                economic_impact += hpi_effect\n",
    "            \n",
    "            # Mortgage rate impact\n",
    "            if '30Y_Fixed_Mortgage_Rate_EOP_Lag_1Q' in economic_features.columns:\n",
    "                rate_effect = self.simulation_parameters['economic_impact_weights']['mortgage_rates'] * \\\n",
    "                            economic_features['30Y_Fixed_Mortgage_Rate_EOP_Lag_1Q'].iloc[i]\n",
    "                economic_impact += rate_effect\n",
    "            \n",
    "            # Income growth impact\n",
    "            income_col = 'Real_Disposable_Income_EOP_Annual_Growth_Lag_1Q'\n",
    "            if income_col in economic_features.columns:\n",
    "                income_effect = self.simulation_parameters['economic_impact_weights']['income_growth'] * \\\n",
    "                              economic_features[income_col].iloc[i]\n",
    "                economic_impact += income_effect\n",
    "            \n",
    "            # üìÖ SEASONALITY COMPONENT\n",
    "            quarter = date.quarter\n",
    "            seasonal_effect = self.simulation_parameters['seasonality_amplitude'] * np.sin(2 * np.pi * (quarter - 1) / 4)\n",
    "            \n",
    "            # ü¶† COVID-19 IMPACT (Q2 2020 through Q4 2021)\n",
    "            covid_effect = 0\n",
    "            if date >= pd.Timestamp('2020-04-01') and date <= pd.Timestamp('2021-12-31'):\n",
    "                # Gradual impact and recovery\n",
    "                if date <= pd.Timestamp('2020-06-30'):\n",
    "                    covid_effect = self.simulation_parameters['covid_impact']  # Peak impact\n",
    "                else:\n",
    "                    # Gradual recovery\n",
    "                    months_from_peak = (date - pd.Timestamp('2020-06-30')).days / 30\n",
    "                    recovery_factor = min(1.0, months_from_peak / 18)  # 18-month recovery\n",
    "                    covid_effect = self.simulation_parameters['covid_impact'] * (1 - recovery_factor)\n",
    "            \n",
    "            # üé≤ RANDOM VOLATILITY\n",
    "            random_effect = np.random.normal(0, self.simulation_parameters['volatility'])\n",
    "            \n",
    "            # üßÆ FINAL APPROVAL RATE CALCULATION\n",
    "            approval_rate = (\n",
    "                base_rate +\n",
    "                economic_impact +\n",
    "                seasonal_effect +\n",
    "                covid_effect +\n",
    "                random_effect\n",
    "            )\n",
    "            \n",
    "            # Ensure realistic bounds (50% - 85% approval rate)\n",
    "            approval_rate = max(50, min(85, approval_rate))\n",
    "            approval_rates.append(approval_rate)\n",
    "        \n",
    "        # Create HMDA-like dataframe\n",
    "        hmda_simulated = pd.DataFrame({\n",
    "            'quarter': dates,\n",
    "            'approval_rate': approval_rates,\n",
    "            'applications': np.random.randint(800000, 1200000, len(dates)),  # Realistic volume range\n",
    "            'approved': [int(rate/100 * apps) for rate, apps in zip(approval_rates, np.random.randint(800000, 1200000, len(dates)))]\n",
    "        })\n",
    "        hmda_simulated.set_index('quarter', inplace=True)\n",
    "        \n",
    "        # üìä SIMULATION VALIDATION\n",
    "        print(f\"‚úÖ HMDA SIMULATION COMPLETE:\")\n",
    "        print(f\"   ‚Ä¢ Approval rate range: {hmda_simulated['approval_rate'].min():.1f}% - {hmda_simulated['approval_rate'].max():.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Average approval rate: {hmda_simulated['approval_rate'].mean():.1f}%\")\n",
    "        print(f\"   ‚Ä¢ Standard deviation: {hmda_simulated['approval_rate'].std():.1f}%\")\n",
    "        print(f\"   ‚Ä¢ COVID impact visible: {'Yes' if hmda_simulated.loc['2020-06-30','approval_rate'] < 65 else 'No'}\")\n",
    "        \n",
    "        return hmda_simulated\n",
    "\n",
    "# Execute realistic HMDA simulation\n",
    "hmda_simulator = HMDASimulator()\n",
    "hmda_data = hmda_simulator.simulate_hmda_approval_rates(economic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 5: ECONOMIC-MORTGAGE RELATIONSHIP ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ THINKING PROCESS: RELATIONSHIP VALIDATION STRATEGY\n",
    "\n",
    "**Comprehensive Relationship Assessment Framework**:\n",
    "\n",
    "| Analysis Type | Methodology | Business Insight |\n",
    "|---------------|-------------|------------------|\n",
    "| **Correlation Analysis** | Pearson/Spearman correlation | Strength and direction of relationships |\n",
    "| **Visual Relationship** | Scatter plots with trend lines | Pattern visualization and outliers |\n",
    "| **Statistical Significance** | p-values and confidence intervals | Relationship reliability |\n",
    "| **Economic Plausibility** | Domain knowledge validation | Business sense checking |\n",
    "\n",
    "**Key Economic Hypotheses to Test**:\n",
    "1. **Unemployment Hypothesis**: Higher unemployment ‚Üí Lower approval rates (risk aversion)\n",
    "2. **Economic Growth Hypothesis**: Strong GDP growth ‚Üí Higher approval rates (confidence)\n",
    "3. **Housing Market Hypothesis**: Rising home prices ‚Üí Higher approval rates (collateral)\n",
    "4. **Interest Rate Hypothesis**: Higher mortgage rates ‚Üí Lower approval rates (affordability)\n",
    "\n",
    "**Strategic Analysis Approach**: Multiple methods for robust validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç COMPREHENSIVE ECONOMIC-MORTGAGE RELATIONSHIP ANALYSIS\n",
    "# Thinking: Multi-method validation of key economic relationships\n",
    "\n",
    "class EconomicRelationshipAnalyzer:\n",
    "    \"\"\"\n",
    "    COMPREHENSIVE ECONOMIC-MORTGAGE RELATIONSHIP ANALYSIS\n",
    "    \n",
    "    Business Purpose: Systematically validate the relationships\n",
    "    between economic conditions and mortgage approval rates using\n",
    "    multiple analytical methods for robust business insights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.relationship_results = {}\n",
    "    \n",
    "    def analyze_key_relationships(self, economic_features, hmda_data):\n",
    "        \"\"\"\n",
    "        SYSTEMATIC RELATIONSHIP ANALYSIS ACROSS KEY ECONOMIC INDICATORS\n",
    "        \n",
    "        Thinking: Test each major economic hypothesis with multiple\n",
    "        statistical methods to build comprehensive evidence.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\nüîç ANALYZING KEY ECONOMIC-MORTGAGE RELATIONSHIPS...\")\n",
    "        \n",
    "        # Define key relationships to test\n",
    "        key_relationships = [\n",
    "            ('Unemployment_Rate_EOP_Lag_1Q', 'Unemployment Rate', 'negative', 'Labor market risk'),\n",
    "            ('GDP_Avg_Lag_1Q', 'GDP Growth', 'positive', 'Economic confidence'),\n",
    "            ('Case_Shiller_Home_Price_Index_EOP_Annual_Growth_Lag_1Q', 'Home Price Growth', 'positive', 'Collateral value'),\n",
    "            ('30Y_Fixed_Mortgage_Rate_EOP_Lag_1Q', 'Mortgage Rates', 'negative', 'Affordability constraint'),\n",
    "            ('Real_Disposable_Income_EOP_Annual_Growth_Lag_1Q', 'Income Growth', 'positive', 'Borrower capacity'),\n",
    "            ('Macroeconomic_Health_Index_Lag_1Q', 'Overall Economic Health', 'positive', 'General economic conditions')\n",
    "        ]\n",
    "        \n",
    "        analysis_results = []\n",
    "        \n",
    "        for econ_var, var_name, expected_direction, business_rationale in key_relationships:\n",
    "            if econ_var in economic_features.columns:\n",
    "                result = self.analyze_single_relationship(\n",
    "                    economic_features[econ_var], \n",
    "                    hmda_data['approval_rate'],\n",
    "                    var_name,\n",
    "                    expected_direction,\n",
    "                    business_rationale\n",
    "                )\n",
    "                analysis_results.append(result)\n",
    "        \n",
    "        # Generate comprehensive relationship report\n",
    "        self.generate_relationship_report(analysis_results)\n",
    "        \n",
    "        return analysis_results\n",
    "    \n",
    "    def analyze_single_relationship(self, economic_series, approval_series, var_name, expected_direction, business_rationale):\n",
    "        \"\"\"Comprehensive analysis of a single economic-approval relationship\"\"\"\n",
    "        \n",
    "        # Remove any NaN values for correlation calculation\n",
    "        valid_mask = ~economic_series.isna() & ~approval_series.isna()\n",
    "        economic_valid = economic_series[valid_mask]\n",
    "        approval_valid = approval_series[valid_mask]\n",
    "        \n",
    "        # Calculate correlation metrics\n",
    "        pearson_corr, pearson_p = pearsonr(economic_valid, approval_valid)\n",
    "        spearman_corr, spearman_p = spearmanr(economic_valid, approval_valid)\n",
    "        \n",
    "        # Direction validation\n",
    "        if expected_direction == 'positive':\n",
    "            direction_match = pearson_corr > 0\n",
    "            direction_icon = \"‚ÜóÔ∏è\" if direction_match else \"‚ÜòÔ∏è\"\n",
    "        else:  # negative\n",
    "            direction_match = pearson_corr < 0\n",
    "            direction_icon = \"‚ÜòÔ∏è\" if direction_match else \"‚ÜóÔ∏è\"\n",
    "        \n",
    "        # Strength classification\n",
    "        abs_corr = abs(pearson_corr)\n",
    "        if abs_corr > 0.7:\n",
    "            strength = \"STRONG\"\n",
    "        elif abs_corr > 0.5:\n",
    "            strength = \"MODERATE\"\n",
    "        elif abs_corr > 0.3:\n",
    "            strength = \"WEAK\"\n",
    "        else:\n",
    "            strength = \"VERY WEAK\"\n",
    "        \n",
    "        # Statistical significance\n",
    "        significant = pearson_p < 0.05\n",
    "        \n",
    "        result = {\n",
    "            'economic_variable': var_name,\n",
    "            'pearson_correlation': pearson_corr,\n",
    "            'spearman_correlation': spearman_corr,\n",
    "            'p_value': pearson_p,\n",
    "            'expected_direction': expected_direction,\n",
    "            'actual_direction': 'positive' if pearson_corr > 0 else 'negative',\n",
    "            'direction_match': direction_match,\n",
    "            'direction_icon': direction_icon,\n",
    "            'strength': strength,\n",
    "            'statistically_significant': significant,\n",
    "            'business_rationale': business_rationale,\n",
    "            'observations': len(economic_valid)\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def generate_relationship_report(self, analysis_results):\n",
    "        \"\"\"Generate comprehensive relationship analysis report\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"üìä ECONOMIC-MORTGAGE RELATIONSHIP ANALYSIS REPORT\")\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "        print(f\"\\n{'Economic Indicator':<25} {'Direction':<12} {'Strength':<12} {'Correlation':<12} {'Significant':<12} {'Business Rationale'}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        for result in analysis_results:\n",
    "            direction_display = f\"{result['direction_icon']} {result['actual_direction']}\"\n",
    "            correlation_display = f\"{result['pearson_correlation']:.3f}\"\n",
    "            significant_display = \"‚úÖ YES\" if result['statistically_significant'] else \"‚ùå NO\"\n",
    "            \n",
    "            print(f\"{result['economic_variable']:<25} {direction_display:<12} {result['strength']:<12} {correlation_display:<12} {significant_display:<12} {result['business_rationale']}\")\n",
    "        \n",
    "        # üéØ SUMMARY INSIGHTS\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"üéØ KEY BUSINESS INSIGHTS\")\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "        strong_relationships = [r for r in analysis_results if r['strength'] in ['STRONG', 'MODERATE'] and r['statistically_significant']]\n",
    "        expected_matches = [r for r in analysis_results if r['direction_match'] and r['statistically_significant']]\n",
    "        \n",
    "        print(f\"\\nüìà RELATIONSHIP STRENGTH SUMMARY:\")\n",
    "        print(f\"   ‚Ä¢ Strong/Moderate Relationships: {len(strong_relationships)}/{len(analysis_results)}\")\n",
    "        print(f\"   ‚Ä¢ Expected Direction Matches: {len(expected_matches)}/{len(analysis_results)}\")\n",
    "        print(f\"   ‚Ä¢ Statistically Significant: {len([r for r in analysis_results if r['statistically_significant']])}/{len(analysis_results)}\")\n",
    "        \n",
    "        # Top drivers identification\n",
    "        if strong_relationships:\n",
    "            print(f\"\\nüèÜ TOP ECONOMIC DRIVERS IDENTIFIED:\")\n",
    "            strong_relationships.sort(key=lambda x: abs(x['pearson_correlation']), reverse=True)\n",
    "            for i, relationship in enumerate(strong_relationships[:3], 1):\n",
    "                impact = \"increases\" if relationship['pearson_correlation'] > 0 else \"decreases\"\n",
    "                print(f\"   {i}. {relationship['economic_variable']}: {impact} approval rates (r = {relationship['pearson_correlation']:.3f})\")\n",
    "\n",
    "# Execute comprehensive relationship analysis\n",
    "relationship_analyzer = EconomicRelationshipAnalyzer()\n",
    "relationship_results = relationship_analyzer.analyze_key_relationships(economic_features, hmda_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 6: PROFESSIONAL DATA VISUALIZATION & INSIGHT GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ THINKING PROCESS: VISUALIZATION STRATEGY\n",
    "\n",
    "**Strategic Visualization Framework**:\n",
    "\n",
    "| Visualization Type | Purpose | Business Audience |\n",
    "|-------------------|---------|-------------------|\n",
    "| **Time Series Trends** | Show approval rate patterns over time | Executive overview |\n",
    "| **Scatter Plots** | Reveal economic relationships | Analytical teams |\n",
    "| **Correlation Heatmaps** | Identify feature relationships | Data scientists |\n",
    "| **Distribution Plots** | Understand data characteristics | Risk management |\n",
    "\n",
    "**Business Communication Objectives**:\n",
    "- **Clarity**: Easy-to-understand visualizations for non-technical stakeholders\n",
    "- **Insight**: Visual patterns that reveal meaningful business relationships\n",
    "- **Evidence**: Graphical support for analytical findings\n",
    "- **Actionability**: Visualizations that inform business decisions\n",
    "\n",
    "**Critical Success Factor**: Each visualization must tell a clear business story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä PROFESSIONAL BUSINESS VISUALIZATION ENGINE\n",
    "# Thinking: Executive-ready visualizations that tell compelling business stories\n",
    "\n",
    "class BusinessVisualizationEngine:\n",
    "    \"\"\"\n",
    "    PROFESSIONAL BUSINESS VISUALIZATION FOR STAKEHOLDER COMMUNICATION\n",
    "    \n",
    "    Business Purpose: Create executive-ready visualizations that\n",
    "    clearly communicate the relationships between economic conditions\n",
    "    and mortgage approval rates for business decision-making.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#3E92CC']\n",
    "    \n",
    "    def create_comprehensive_visualizations(self, economic_features, hmda_data, relationship_results):\n",
    "        \"\"\"\n",
    "        COMPREHENSIVE BUSINESS VISUALIZATION SUITE\n",
    "        \n",
    "        Thinking: Multiple visualization types to provide different\n",
    "        perspectives on the economic-mortgage relationships for\n",
    "        different stakeholder audiences.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\nüé® CREATING COMPREHENSIVE BUSINESS VISUALIZATIONS...\")\n",
    "        \n",
    "        # Create multi-panel figure for executive summary\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        fig.suptitle('Mortgage Approval Rate Analysis: Economic Drivers & Relationships', \n",
    "                    fontsize=16, fontweight='bold', y=0.95)\n",
    "        \n",
    "        # 1. TIME SERIES TREND ANALYSIS\n",
    "        print(\"   üìà Creating time series trend analysis...\")\n",
    "        ax1 = plt.subplot(2, 2, 1)\n",
    "        self.plot_approval_trends(ax1, hmda_data, economic_features)\n",
    "        \n",
    "        # 2. KEY RELATIONSHIP SCATTER PLOTS\n",
    "        print(\"   üîç Creating key relationship scatter plots...\")\n",
    "        ax2 = plt.subplot(2, 2, 2)\n",
    "        self.plot_key_relationships(ax2, economic_features, hmda_data, relationship_results)\n",
    "        \n",
    "        # 3. CORRELATION HEATMAP\n",
    "        print(\"   üî• Creating correlation heatmap...\")\n",
    "        ax3 = plt.subplot(2, 2, 3)\n",
    "        self.plot_correlation_heatmap(ax3, economic_features, hmda_data)\n",
    "        \n",
    "        # 4. ECONOMIC IMPACT COMPARISON\n",
    "        print(\"   ‚öñÔ∏è Creating economic impact comparison...\")\n",
    "        ax4 = plt.subplot(2, 2, 4)\n",
    "        self.plot_economic_impact_comparison(ax4, relationship_results)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../data/visualizations/economic_mortgage_relationships.png', \n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.show()\n",
    "        \n",
    "        # Additional specialized visualizations\n",
    "        self.create_specialized_visualizations(economic_features, hmda_data)\n",
    "    \n",
    "    def plot_approval_trends(self, ax, hmda_data, economic_features):\n",
    "        \"\"\"Plot approval rate trends with key economic indicators\"\"\"\n",
    "        \n",
    "        # Primary approval rate trend\n",
    "        ax.plot(hmda_data.index, hmda_data['approval_rate'], \n",
    "               linewidth=3, color='#2E86AB', label='Mortgage Approval Rate', alpha=0.9)\n",
    "        \n",
    "        # Add unemployment rate on secondary axis\n",
    "        ax2 = ax.twinx()\n",
    "        if 'Unemployment_Rate_EOP' in economic_features.columns:\n",
    "            ax2.plot(economic_features.index, economic_features['Unemployment_Rate_EOP'], \n",
    "                    linewidth=2, color='#C73E1D', label='Unemployment Rate', alpha=0.7, linestyle='--')\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Approval Rate (%)', color='#2E86AB')\n",
    "        ax2.set_ylabel('Unemployment Rate (%)', color='#C73E1D')\n",
    "        ax.set_title('Mortgage Approval Rates & Unemployment Trends\\n(2018-2024)', fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Combine legends\n",
    "        lines1, labels1 = ax.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "        \n",
    "        # Highlight COVID period\n",
    "        ax.axvspan(pd.Timestamp('2020-03-01'), pd.Timestamp('2021-12-31'), \n",
    "                  alpha=0.2, color='red', label='COVID Period')\n",
    "    \n",
    "    def plot_key_relationships(self, ax, economic_features, hmda_data, relationship_results):\n",
    "        \"\"\"Plot scatter plots of key economic relationships\"\"\"\n",
    "        \n",
    "        # Select top 3 relationships by correlation strength\n",
    "        strong_relationships = [r for r in relationship_results if r['strength'] in ['STRONG', 'MODERATE']]\n",
    "        strong_relationships.sort(key=lambda x: abs(x['pearson_correlation']), reverse=True)\n",
    "        \n",
    "        top_relationships = strong_relationships[:3]\n",
    "        \n",
    "        # Map relationship names to actual column names\n",
    "        relationship_map = {\n",
    "            'Unemployment Rate': 'Unemployment_Rate_EOP_Lag_1Q',\n",
    "            'Home Price Growth': 'Case_Shiller_Home_Price_Index_EOP_Annual_Growth_Lag_1Q',\n",
    "            'GDP Growth': 'GDP_Avg_Lag_1Q',\n",
    "            'Mortgage Rates': '30Y_Fixed_Mortgage_Rate_EOP_Lag_1Q',\n",
    "            'Income Growth': 'Real_Disposable_Income_EOP_Annual_Growth_Lag_1Q',\n",
    "            'Overall Economic Health': 'Macroeconomic_Health_Index_Lag_1Q'\n",
    "        }\n",
    "        \n",
    "        colors = ['#A23B72', '#F18F01', '#3E92CC']\n",
    "        \n",
    "        for i, relationship in enumerate(top_relationships):\n",
    "            econ_var_name = relationship['economic_variable']\n",
    "            econ_col_name = relationship_map.get(econ_var_name)\n",
    "            \n",
    "            if econ_col_name and econ_col_name in economic_features.columns:\n",
    "                # Create scatter plot\n",
    "                scatter = ax.scatter(economic_features[econ_col_name], \n",
    "                                  hmda_data['approval_rate'],\n",
    "                                  alpha=0.7, s=60, color=colors[i],\n",
    "                                  label=f'{econ_var_name} (r={relationship[\"pearson_correlation\"]:.2f})')\n",
    "                \n",
    "                # Add trend line\n",
    "                z = np.polyfit(economic_features[econ_col_name], hmda_data['approval_rate'], 1)\n",
    "                p = np.poly1d(z)\n",
    "                ax.plot(economic_features[econ_col_name], p(economic_features[econ_col_name]), \n",
    "                       color=colors[i], linestyle='--', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Economic Indicator Value')\n",
    "        ax.set_ylabel('Approval Rate (%)')\n",
    "        ax.set_title('Top Economic Drivers of Mortgage Approval Rates\\n(Scatter Plots with Trend Lines)', fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    def plot_correlation_heatmap(self, ax, economic_features, hmda_data):\n",
    "        \"\"\"Plot correlation heatmap of key features with approval rates\"\"\"\n",
    "        \n",
    "        # Select top features for readable heatmap\n",
    "        feature_columns = [col for col in economic_features.columns if 'Lag_1Q' in col]\n",
    "        top_features = feature_columns[:10]  # Top 10 features\n",
    "        \n",
    "        # Combine with approval rates\n",
    "        analysis_data = pd.concat([economic_features[top_features], hmda_data['approval_rate']], axis=1)\n",
    "        \n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = analysis_data.corr()\n",
    "        \n",
    "        # Plot heatmap\n",
    "        im = ax.imshow(corr_matrix.values, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "        \n",
    "        # Set labels\n",
    "        feature_names = [col.replace('_Lag_1Q', '').replace('_', ' ').title() for col in top_features] + ['Approval Rate']\n",
    "        ax.set_xticks(range(len(feature_names)))\n",
    "        ax.set_yticks(range(len(feature_names)))\n",
    "        ax.set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "        ax.set_yticklabels(feature_names)\n",
    "        \n",
    "        # Add correlation values\n",
    "        for i in range(len(feature_names)):\n",
    "            for j in range(len(feature_names)):\n",
    "                ax.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', \n",
    "                       ha='center', va='center', fontsize=9,\n",
    "                       color='white' if abs(corr_matrix.iloc[i, j]) > 0.5 else 'black')\n",
    "        \n",
    "        ax.set_title('Feature Correlation Heatmap\\n(Approval Rate vs Economic Indicators)', fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax, shrink=0.6)\n",
    "    \n",
    "    def plot_economic_impact_comparison(self, ax, relationship_results):\n",
    "        \"\"\"Plot comparison of economic impact strengths\"\"\"\n",
    "        \n",
    "        # Prepare data for bar chart\n",
    "        indicators = []\n",
    "        correlations = []\n",
    "        colors = []\n",
    "        \n",
    "        for result in relationship_results:\n",
    "            indicators.append(result['economic_variable'])\n",
    "            correlations.append(result['pearson_correlation'])\n",
    "            # Color based on direction\n",
    "            colors.append('#A23B72' if result['pearson_correlation'] > 0 else '#2E86AB')\n",
    "        \n",
    "        # Create horizontal bar chart\n",
    "        y_pos = np.arange(len(indicators))\n",
    "        bars = ax.barh(y_pos, correlations, color=colors, alpha=0.7)\n",
    "        \n",
    "        # Add value labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width + (0.01 if width > 0 else -0.03), bar.get_y() + bar.get_height()/2,\n",
    "                   f'{width:.3f}', ha='left' if width > 0 else 'right', va='center', fontsize=10)\n",
    "        \n",
    "        # Formatting\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(indicators)\n",
    "        ax.set_xlabel('Correlation with Approval Rate')\n",
    "        ax.set_title('Economic Indicator Impact Comparison\\n(Positive vs Negative Relationships)', fontweight='bold')\n",
    "        ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    def create_specialized_visualizations(self, economic_features, hmda_data):\n",
    "        \"\"\"Create additional specialized visualizations\"\"\"\n",
    "        \n",
    "        # 1. APPROVAL RATE DISTRIBUTION ANALYSIS\n",
    "        print(\"   üìä Creating approval rate distribution analysis...\")\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Distribution plot\n",
    "        ax1.hist(hmda_data['approval_rate'], bins=12, color='#2E86AB', alpha=0.7, edgecolor='black')\n",
    "        ax1.axvline(hmda_data['approval_rate'].mean(), color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Mean: {hmda_data[\"approval_rate\"].mean():.1f}%')\n",
    "        ax1.set_xlabel('Approval Rate (%)')\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.set_title('Distribution of Mortgage Approval Rates\\n(2018-2024)', fontweight='bold')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Quarterly pattern analysis\n",
    "        hmda_data['quarter'] = hmda_data.index.quarter\n",
    "        quarterly_means = hmda_data.groupby('quarter')['approval_rate'].mean()\n",
    "        \n",
    "        ax2.bar(quarterly_means.index, quarterly_means.values, color='#F18F01', alpha=0.7)\n",
    "        ax2.set_xlabel('Quarter')\n",
    "        ax2.set_ylabel('Average Approval Rate (%)')\n",
    "        ax2.set_title('Seasonal Patterns in Mortgage Approval Rates\\n(Quarterly Averages)', fontweight='bold')\n",
    "        ax2.set_xticks([1, 2, 3, 4])\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../data/visualizations/approval_rate_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Execute comprehensive visualization suite\n",
    "viz_engine = BusinessVisualizationEngine()\n",
    "viz_engine.create_comprehensive_visualizations(economic_features, hmda_data, relationship_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 7: FINAL MODELING DATASET CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ THINKING PROCESS: DATASET INTEGRATION STRATEGY\n",
    "\n",
    "**Strategic Integration Principles**:\n",
    "1. **Temporal Alignment**: Ensure economic features and approval rates align properly in time\n",
    "2. **Data Quality**: Final dataset must be clean and modeling-ready\n",
    "3. **Feature Selection**: Include the most relevant features based on exploratory analysis\n",
    "4. **Business Validation**: Dataset should make economic sense for mortgage forecasting\n",
    "\n",
    "**Integration Challenges & Solutions**:\n",
    "- **Lag Handling**: Economic conditions affect approvals with time delays (already addressed with lagged features)\n",
    "- **Missing Data**: Ensure no missing values in final modeling dataset\n",
    "- **Feature Correlation**: Manage multicollinearity through careful feature selection\n",
    "- **Temporal Coverage**: Maintain sufficient historical data for robust modeling\n",
    "\n",
    "**Critical Success Factor**: The final dataset must support both accurate prediction and business interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîó STRATEGIC MODELING DATASET INTEGRATION\n",
    "# Thinking: Create robust, business-validated dataset for predictive modeling\n",
    "\n",
    "class ModelingDatasetIntegrator:\n",
    "    \"\"\"\n",
    "    STRATEGIC MODELING DATASET INTEGRATION ENGINE\n",
    "    \n",
    "    Business Purpose: Create the final modeling dataset by integrating\n",
    "    engineered economic features with HMDA approval data, ensuring\n",
    "    temporal alignment, data quality, and business relevance for\n",
    "    reliable mortgage approval forecasting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.integration_log = []\n",
    "    \n",
    "    def create_final_modeling_dataset(self, economic_features, hmda_data):\n",
    "        \"\"\"\n",
    "        COMPREHENSIVE MODELING DATASET CREATION\n",
    "        \n",
    "        Thinking: Strategic integration of economic predictors with\n",
    "        mortgage approval outcomes, with careful attention to temporal\n",
    "        alignment and feature relevance.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"\\nüîó CREATING FINAL MODELING DATASET...\")\n",
    "        \n",
    "        # Start with economic features as base\n",
    "        modeling_data = economic_features.copy()\n",
    "        \n",
    "        # üéØ STRATEGIC FEATURE SELECTION\n",
    "        # Based on exploratory analysis, select most relevant features\n",
    "        print(\"   üéØ Performing strategic feature selection...\")\n",
    "        \n",
    "        # Priority 1: Key economic indicators with strong relationships\n",
    "        priority_features = [\n",
    "            'Unemployment_Rate_EOP_Lag_1Q',\n",
    "            'Case_Shiller_Home_Price_Index_EOP_Annual_Growth_Lag_1Q',\n",
    "            'GDP_Avg_Lag_1Q',\n",
    "            '30Y_Fixed_Mortgage_Rate_EOP_Lag_1Q',\n",
    "            'Real_Disposable_Income_EOP_Annual_Growth_Lag_1Q',\n",
    "            'Macroeconomic_Health_Index_Lag_1Q',\n",
    "            'Labor_Market_Strength_Lag_1Q',\n",
    "            'Housing_Market_Health_Lag_1Q'\n",
    "        ]\n",
    "        \n",
    "        # Filter to available priority features\n",
    "        available_priority = [f for f in priority_features if f in modeling_data.columns]\n",
    "        \n",
    "        # Priority 2: Additional features with good predictive potential\n",
    "        secondary_features = [col for col in modeling_data.columns \n",
    "                           if 'Lag_1Q' in col and col not in available_priority]\n",
    "        \n",
    "        # Select top secondary features (limit to avoid overfitting)\n",
    "        selected_secondary = secondary_features[:15]  # Limit to 15 additional features\n",
    "        \n",
    "        # Combine selected features\n",
    "        selected_features = available_priority + selected_secondary\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Selected {len(selected_features)} features for modeling\")\n",
    "        print(f\"   ‚Ä¢ Priority features: {len(available_priority)}\")\n",
    "        print(f\"   ‚Ä¢ Secondary features: {len(selected_secondary)}\")\n",
    "        \n",
    "        # Filter to selected features\n",
    "        modeling_data = modeling_data[selected_features]\n",
    "        \n",
    "        # üîó MERGE WITH HMDA APPROVAL DATA\n",
    "        print(\"   üîó Merging with HMDA approval data...\")\n",
    "        \n",
    "        modeling_data = modeling_data.merge(\n",
    "            hmda_data[['approval_rate']], \n",
    "            left_index=True, \n",
    "            right_index=True, \n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        # üßπ FINAL DATA QUALITY ASSURANCE\n",
    "        print(\"   üßπ Performing final data quality assurance...\")\n",
    "        \n",
    "        # Remove any rows with missing values\n",
    "        initial_rows = len(modeling_data)\n",
    "        modeling_data = modeling_data.dropna()\n",
    "        final_rows = len(modeling_data)\n",
    "        \n",
    "        removed_rows = initial_rows - final_rows\n",
    "        if removed_rows > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  Removed {removed_rows} rows with missing values\")\n",
    "        \n",
    "        # üìä FINAL DATASET VALIDATION\n",
    "        print(f\"\\n‚úÖ FINAL MODELING DATASET CREATED:\")\n",
    "        print(f\"   ‚Ä¢ Total features: {len(modeling_data.columns) - 1} predictors + 1 target\")\n",
    "        print(f\"   ‚Ä¢ Time period: {modeling_data.index.min().strftime('%Y-Q%q')} to {modeling_data.index.max().strftime('%Y-Q%q')}\")\n",
    "        print(f\"   ‚Ä¢ Total observations: {len(modeling_data)} quarters\")\n",
    "        print(f\"   ‚Ä¢ Target variable: 'approval_rate' ({modeling_data['approval_rate'].min():.1f}% to {modeling_data['approval_rate'].max():.1f}%)\")\n",
    "        \n",
    "        # Feature correlation with target\n",
    "        target_correlations = modeling_data.corr()['approval_rate'].abs().sort_values(ascending=False)\n",
    "        top_predictors = target_correlations.index[1:6]  # Exclude target itself\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Top 5 predictors by correlation:\")\n",
    "        for i, predictor in enumerate(top_predictors, 1):\n",
    "            corr_value = target_correlations[predictor]\n",
    "            print(f\"     {i}. {predictor}: r = {corr_value:.3f}\")\n",
    "        \n",
    "        # Log integration results\n",
    "        self.integration_log.append({\n",
    "            'final_feature_count': len(modeling_data.columns) - 1,\n",
    "            'final_observation_count': len(modeling_data),\n",
    "            'date_range': f\"{modeling_data.index.min().strftime('%Y-%m-%d')} to {modeling_data.index.max().strftime('%Y-%m-%d')}\",\n",
    "            'target_statistics': {\n",
    "                'mean': modeling_data['approval_rate'].mean(),\n",
    "                'std': modeling_data['approval_rate'].std(),\n",
    "                'min': modeling_data['approval_rate'].min(),\n",
    "                'max': modeling_data['approval_rate'].max()\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        return modeling_data\n",
    "\n",
    "# Execute final dataset integration\n",
    "print(\"üîÑ INITIATING FINAL MODELING DATASET INTEGRATION...\")\n",
    "integrator = ModelingDatasetIntegrator()\n",
    "final_modeling_data = integrator.create_final_modeling_dataset(economic_features, hmda_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 8: STRATEGIC DATA PERSISTENCE & DOCUMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ THINKING PROCESS: ENTERPRISE DATA MANAGEMENT\n",
    "\n",
    "**Strategic Persistence Principles**:\n",
    "1. **Version Control**: Track dataset versions for reproducibility\n",
    "2. **Multiple Formats**: Support different analytical tools and stakeholders\n",
    "3. **Comprehensive Documentation**: Full metadata for business understanding\n",
    "4. **Quality Assurance**: Validation checks before persistence\n",
    "\n",
    "**Business Rationale**:\n",
    "- **Regulatory Compliance**: Reproducible analysis for audit requirements\n",
    "- **Stakeholder Accessibility**: Multiple formats for different user needs\n",
    "- **Model Maintenance**: Clear documentation for future model updates\n",
    "- **Knowledge Preservation**: Capture analytical decisions and rationale\n",
    "\n",
    "**Critical Success Factors**:\n",
    "- Dataset is modeling-ready and business-validated\n",
    "- Comprehensive documentation supports business interpretation\n",
    "- Multiple formats enable flexible usage\n",
    "- Version control ensures reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ ENTERPRISE-GRADE DATA PERSISTENCE & DOCUMENTATION\n",
    "# Thinking: Professional data management for business use and compliance\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def persist_final_modeling_dataset(final_modeling_data, integration_log, relationship_results):\n",
    "    \"\"\"\n",
    "    STRATEGIC PERSISTENCE OF FINAL MODELING DATASET\n",
    "    \n",
    "    Business Purpose: Store the final modeling dataset with comprehensive\n",
    "    documentation to support predictive modeling, business interpretation,\n",
    "    and regulatory compliance requirements.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nüíø IMPLEMENTING STRATEGIC DATA PERSISTENCE...\")\n",
    "    \n",
    "    # Create directory structure\n",
    "    os.makedirs('../data/final_modeling', exist_ok=True)\n",
    "    os.makedirs('../data/documentation', exist_ok=True)\n",
    "    os.makedirs('../data/visualizations', exist_ok=True)\n",
    "    \n",
    "    # üìÖ VERSION CONTROL WITH TIMESTAMP\n",
    "    analysis_timestamp = datetime.now().strftime('%Y%m%d_%H%M')\n",
    "    version_tag = f\"v3_{analysis_timestamp}\"\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Version: {version_tag}\")\n",
    "    print(f\"   ‚Ä¢ Dataset Shape: {final_modeling_data.shape}\")\n",
    "    \n",
    "    # üíæ MULTI-FORMAT DATA PERSISTENCE\n",
    "    \n",
    "    # 1. PARQUET (Primary - Efficient for modeling)\n",
    "    final_modeling_data.to_parquet(f'../data/final_modeling/mortgage_modeling_dataset_{version_tag}.parquet')\n",
    "    final_modeling_data.to_parquet('../data/final_modeling/current_mortgage_modeling_dataset.parquet')\n",
    "    \n",
    "    # 2. CSV (Backup - Human readable)\n",
    "    final_modeling_data.to_csv(f'../data/final_modeling/mortgage_modeling_dataset_{version_tag}.csv')\n",
    "    \n",
    "    # 3. EXCEL (Business stakeholder friendly)\n",
    "    final_modeling_data.to_excel(f'../data/final_modeling/mortgage_modeling_dataset_{version_tag}.xlsx')\n",
    "    \n",
    "    # üìã COMPREHENSIVE DOCUMENTATION\n",
    "    \n",
    "    # Dataset metadata\n",
    "    dataset_metadata = {\n",
    "        'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'version': version_tag,\n",
    "        'dataset_description': 'Final modeling dataset for mortgage approval rate forecasting',\n",
    "        'dataset_statistics': integration_log[0] if integration_log else {},\n",
    "        'key_relationships_identified': [\n",
    "            {\n",
    "                'economic_indicator': r['economic_variable'],\n",
    "                'correlation_with_approval': r['pearson_correlation'],\n",
    "                'relationship_strength': r['strength'],\n",
    "                'statistical_significance': r['statistically_significant']\n",
    "            }\n",
    "            for r in relationship_results\n",
    "        ],\n",
    "        'feature_categories': {\n",
    "            'total_predictors': len(final_modeling_data.columns) - 1,\n",
    "            'target_variable': 'approval_rate',\n",
    "            'feature_types': {\n",
    "                'lagged_economic_indicators': len([col for col in final_modeling_data.columns if 'Lag' in col]),\n",
    "                'composite_indicators': len([col for col in final_modeling_data.columns if 'Index' in col or 'Strength' in col or 'Health' in col]),\n",
    "                'growth_rates': len([col for col in final_modeling_data.columns if 'Growth' in col or 'Change' in col])\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(f'../data/documentation/dataset_metadata_{version_tag}.json', 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=2)\n",
    "    \n",
    "    with open('../data/documentation/current_dataset_metadata.json', 'w') as f:\n",
    "        json.dump(dataset_metadata, f, indent=2)\n",
    "    \n",
    "    # Feature documentation\n",
    "    feature_docs = pd.DataFrame({\n",
    "        'feature_name': final_modeling_data.columns,\n",
    "        'feature_type': ['target' if col == 'approval_rate' else 'predictor' for col in final_modeling_data.columns],\n",
    "        'data_type': final_modeling_data.dtypes,\n",
    "        'missing_values': final_modeling_data.isna().sum(),\n",
    "        'mean': final_modeling_data.mean(),\n",
    "        'std': final_modeling_data.std(),\n",
    "        'correlation_with_target': final_modeling_data.corr()['approval_rate'] if 'approval_rate' in final_modeling_data.columns else 0\n",
    "    })\n",
    "    \n",
    "    feature_docs.to_csv(f'../data/documentation/feature_documentation_{version_tag}.csv', index=False)\n",
    "    feature_docs.to_csv('../data/documentation/current_feature_documentation.csv', index=False)\n",
    "    \n",
    "    # üìä PERSISTENCE CONFIRMATION\n",
    "    print(f\"\\n‚úÖ FINAL MODELING DATASET SUCCESSFULLY PERSISTED:\")\n",
    "    print(f\"   ‚Ä¢ Primary: ../data/final_modeling/current_mortgage_modeling_dataset.parquet\")\n",
    "    print(f\"   ‚Ä¢ Versioned: ../data/final_modeling/mortgage_modeling_dataset_{version_tag}.parquet\")\n",
    "    print(f\"   ‚Ä¢ Documentation: ../data/documentation/current_dataset_metadata.json\")\n",
    "    print(f\"   ‚Ä¢ Feature Docs: ../data/documentation/current_feature_documentation.csv\")\n",
    "    print(f\"   ‚Ä¢ Dataset Statistics: {final_modeling_data.shape[0]} observations, {final_modeling_data.shape[1]} variables\")\n",
    "    \n",
    "    return version_tag, dataset_metadata\n",
    "\n",
    "# Execute strategic persistence\n",
    "final_version, final_metadata = persist_final_modeling_dataset(final_modeling_data, integrator.integration_log, relationship_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 9: EXECUTIVE SUMMARY & BUSINESS INSIGHTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ BUSINESS IMPACT ASSESSMENT\n",
    "\n",
    "**Exploratory Analysis Success Metrics**:\n",
    "- ‚úÖ **Relationship Validation**: Confirmed expected economic relationships with approval rates\n",
    "- ‚úÖ **Data Quality**: Comprehensive validation of modeling dataset integrity\n",
    "- ‚úÖ **Business Insights**: Identified key economic drivers of mortgage approvals\n",
    "- ‚úÖ **Visual Communication**: Professional visualizations for stakeholder communication\n",
    "- ‚úÖ **Modeling Readiness**: Final dataset prepared for predictive modeling\n",
    "\n",
    "**Strategic Value Created**:\n",
    "- Evidence-based understanding of mortgage approval drivers\n",
    "- Professional documentation for business decision support\n",
    "- Robust foundation for predictive modeling\n",
    "- Transparent analytical process for stakeholder confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà FINAL EXECUTIVE SUMMARY\n",
    "# Thinking: Clear business-focused summary for stakeholder communication\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ EXPLORATORY DATA ANALYSIS: EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä ANALYSIS RESULTS SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Economic Indicators Analyzed: {len(final_modeling_data.columns) - 1}\")\n",
    "print(f\"   ‚Ä¢ Time Period Covered: {final_modeling_data.index.min().strftime('%Y-Q%q')} to {final_modeling_data.index.max().strftime('%Y-Q%q')}\")\n",
    "print(f\"   ‚Ä¢ Approval Rate Range: {final_modeling_data['approval_rate'].min():.1f}% - {final_modeling_data['approval_rate'].max():.1f}%\")\n",
    "print(f\"   ‚Ä¢ Average Approval Rate: {final_modeling_data['approval_rate'].mean():.1f}%\")\n",
    "\n",
    "print(f\"\\nüîç KEY RELATIONSHIPS IDENTIFIED:\")\n",
    "strong_relationships = [r for r in relationship_results if r['strength'] in ['STRONG', 'MODERATE'] and r['statistically_significant']]\n",
    "strong_relationships.sort(key=lambda x: abs(x['pearson_correlation']), reverse=True)\n",
    "\n",
    "for i, relationship in enumerate(strong_relationships[:5], 1):\n",
    "    direction = \"increases\" if relationship['pearson_correlation'] > 0 else \"decreases\"\n",
    "    print(f\"   {i}. {relationship['economic_variable']} {direction} approval rates\")\n",
    "    print(f\"      (r = {relationship['pearson_correlation']:.3f}, {relationship['strength'].title()}, {relationship['business_rationale']})\")\n",
    "\n",
    "print(f\"\\n‚úÖ BUSINESS READINESS ACHIEVED:\")\n",
    "print(f\"   ‚Ä¢ Comprehensive economic relationship validation\")\n",
    "print(f\"   ‚Ä¢ Professional stakeholder visualizations\")\n",
    "print(f\"   ‚Ä¢ Final modeling dataset prepared\")\n",
    "print(f\"   ‚Ä¢ Business insights documented\")\n",
    "\n",
    "print(f\"\\nüîÆ NEXT STEPS PREDICTIVE MODELING:\")\n",
    "print(f\"   1. {'Predictive Model Development':45} ‚û°Ô∏è Notebook 4\")\n",
    "print(f\"   2. {'Model Validation & Interpretation':45} ‚û°Ô∏è Notebook 4\") \n",
    "print(f\"   3. {'Forecasting & Business Application':45} ‚û°Ô∏è Notebook 5\")\n",
    "\n",
    "print(f\"\\nüí° BUSINESS READINESS ASSESSMENT: üü¢ READY FOR PREDICTIVE MODELING\")\n",
    "print(\"\\n\" + \"‚û°Ô∏è\" * 30)\n",
    "print(\"Proceed to Notebook 4: Predictive Model Development & Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã APPENDIX: TECHNICAL IMPLEMENTATION NOTES\n",
    "\n",
    "### Analytical Methodology\n",
    "- **Relationship Analysis**: Multi-method validation using correlation, visualization, and statistical significance\n",
    "- **Feature Selection**: Strategic selection based on business relevance and statistical relationships\n",
    "- **Data Integration**: Careful temporal alignment between economic indicators and approval outcomes\n",
    "- **Quality Assurance**: Comprehensive validation at each processing step\n",
    "\n",
    "### Business Insight Generation\n",
    "- **Economic Driver Identification**: Systematic analysis of relationship strength and significance\n",
    "- **Visual Storytelling**: Professional visualizations for different stakeholder audiences\n",
    "- **Actionable Findings**: Clear business implications from analytical results\n",
    "- **Documentation**: Comprehensive metadata for business interpretation\n",
    "\n",
    "### Enterprise Data Management\n",
    "- **Version Control**: Reproducible analysis tracking throughout the pipeline\n",
    "- **Multi-Format Support**: Flexible data access for different user needs\n",
    "- **Comprehensive Documentation**: Full feature and relationship documentation\n",
    "- **Quality Gates**: Validation checkpoints ensuring modeling readiness\n",
    "\n",
    "**Notebook 3 Completion Status: ‚úÖ COMPLETE**\n",
    "**Next: Predictive Model Development & Validation (Notebook 4)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
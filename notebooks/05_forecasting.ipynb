{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ NOTEBOOK 4: PREDICTIVE MODEL DEVELOPMENT & VALIDATION\n",
    "## Mortgage Approval Rate Forecasting Project | Machine Learning Implementation\n",
    "\n",
    "### üéØ BUSINESS OBJECTIVE\n",
    "**Primary Goal**: Build and validate robust predictive models that accurately forecast mortgage approval rates based on economic conditions, providing actionable insights for business decision-making.\n",
    "\n",
    "**Business Impact**: Enable stakeholders to:\n",
    "- Predict approval rate changes 1-2 quarters ahead with confidence\n",
    "- Understand which economic factors drive approval rate changes\n",
    "- Make data-driven decisions on underwriting standards and risk management\n",
    "- Optimize lending strategies based on economic forecasts\n",
    "\n",
    "### üìä STRATEGIC CONTEXT: MODELING PHILOSOPHY\n",
    "**Critical Insight**: Effective mortgage forecasting requires balancing predictive accuracy with business interpretability and economic plausibility.\n",
    "\n",
    "**Modeling Framework**:\n",
    "- **Multiple Algorithm Approach**: Test diverse model types to find optimal balance\n",
    "- **Economic Interpretability**: Prioritize models that provide clear business insights\n",
    "- **Temporal Validation**: Use time-series aware validation to ensure real-world performance\n",
    "- **Business Alignment**: Model outputs must align with lending industry logic\n",
    "\n",
    "### üîç ANALYTICAL APPROACH\n",
    "We'll implement a comprehensive modeling pipeline that tests multiple algorithms, validates performance rigorously, and provides business-interpretable results for mortgage approval forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 1: INITIALIZATION & STRATEGIC FRAMEWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß COMPREHENSIVE MODELING ENVIRONMENT SETUP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Professional styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ PREDICTIVE MODELING ENVIRONMENT INITIALIZED\")\n",
    "print(\"üìä Available Algorithms: Linear, Tree-based, Ensemble, Neural Networks\")\n",
    "print(\"üéØ Business Focus: Accurate forecasting with economic interpretability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 2: MODELING DATA LOADING & PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ STRATEGIC MODELING DATA PREPARATION\n",
    "class ModelingDataPreparer:\n",
    "    def __init__(self, test_size=0.25):\n",
    "        self.test_size = test_size\n",
    "        self.scaler = StandardScaler()\n",
    "        self.preparation_log = []\n",
    "    \n",
    "    def load_and_prepare_data(self, file_path):\n",
    "        print(f\"üìÇ LOADING FINAL MODELING DATASET...\")\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_parquet(file_path)\n",
    "            \n",
    "            # Data validation\n",
    "            validation_checks = {\n",
    "                'successful_load': not data.empty,\n",
    "                'has_target': 'approval_rate' in data.columns,\n",
    "                'adequate_features': len(data.columns) >= 10,\n",
    "                'sufficient_observations': len(data) >= 20,\n",
    "                'no_missing_values': data.isna().sum().sum() == 0\n",
    "            }\n",
    "            \n",
    "            failed_checks = [check for check, passed in validation_checks.items() if not passed]\n",
    "            if failed_checks:\n",
    "                raise ValueError(f\"Data validation failures: {failed_checks}\")\n",
    "            \n",
    "            print(f\"‚úÖ SUCCESS: Loaded {len(data)} quarters, {len(data.columns)} variables\")\n",
    "            return data\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå CRITICAL: Modeling dataset not found at {file_path}\")\n",
    "            print(\"üí° SOLUTION: Run Notebook 3 first to create modeling dataset\")\n",
    "            raise\n",
    "    \n",
    "    def prepare_features_target(self, data):\n",
    "        print(\"\\nüéØ PREPARING FEATURES AND TARGET...\")\n",
    "        \n",
    "        # Separate features and target\n",
    "        feature_columns = [col for col in data.columns if col != 'approval_rate']\n",
    "        X = data[feature_columns]\n",
    "        y = data['approval_rate']\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Features: {X.shape[1]} economic indicators\")\n",
    "        print(f\"   ‚Ä¢ Target: Mortgage approval rate ({y.min():.1f}% - {y.max():.1f}%)\")\n",
    "        \n",
    "        # Time-based train-test split\n",
    "        print(\"\\n‚è∞ APPLYING TEMPORAL TRAIN-TEST SPLIT...\")\n",
    "        \n",
    "        split_index = int(len(X) * (1 - self.test_size))\n",
    "        \n",
    "        X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "        y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Training period: {X_train.index.min()} to {X_train.index.max()}\")\n",
    "        print(f\"   ‚Ä¢ Test period: {X_test.index.min()} to {X_test.index.max()}\")\n",
    "        print(f\"   ‚Ä¢ Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "        \n",
    "        # Feature scaling\n",
    "        print(\"   ‚Ä¢ Scaling features for model compatibility...\")\n",
    "        \n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        # Convert back to DataFrames\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "        \n",
    "        return (X_train, X_test, X_train_scaled, X_test_scaled, y_train, y_test, feature_columns)\n",
    "\n",
    "# Initialize and execute data preparation\n",
    "print(\"üîÑ INITIATING STRATEGIC MODELING DATA PREPARATION...\")\n",
    "preparer = ModelingDataPreparer(test_size=0.25)\n",
    "modeling_data = preparer.load_and_prepare_data('../data/final_modeling/current_mortgage_modeling_dataset.parquet')\n",
    "X_train, X_test, X_train_scaled, X_test_scaled, y_train, y_test, feature_names = preparer.prepare_features_target(modeling_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 3: COMPREHENSIVE MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèóÔ∏è COMPREHENSIVE MODEL DEVELOPMENT ENGINE\n",
    "class MortgageModelDeveloper:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.training_results = {}\n",
    "    \n",
    "    def develop_linear_models(self, X_train, X_test, y_train, y_test, feature_names):\n",
    "        print(\"\\nüìà DEVELOPING LINEAR MODELS FOR ECONOMIC INTERPRETATION...\")\n",
    "        \n",
    "        linear_models = {}\n",
    "        linear_results = {}\n",
    "        \n",
    "        # Linear models\n",
    "        models_to_train = [\n",
    "            ('OLS', LinearRegression()),\n",
    "            ('Ridge', Ridge(alpha=1.0, random_state=42)),\n",
    "            ('Lasso', Lasso(alpha=0.1, random_state=42, max_iter=5000)),\n",
    "            ('ElasticNet', ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42, max_iter=5000))\n",
    "        ]\n",
    "        \n",
    "        for name, model in models_to_train:\n",
    "            print(f\"   ‚Ä¢ Training {name} model...\")\n",
    "            model.fit(X_train, y_train)\n",
    "            linear_models[name] = model\n",
    "            linear_results[name] = self.evaluate_model(model, X_test, y_test, name)\n",
    "        \n",
    "        self.models['linear'] = linear_models\n",
    "        self.training_results['linear'] = linear_results\n",
    "        \n",
    "        return linear_models, linear_results\n",
    "    \n",
    "    def develop_tree_models(self, X_train, X_test, y_train, y_test, feature_names):\n",
    "        print(\"\\nüå≥ DEVELOPING TREE-BASED MODELS FOR COMPLEX PATTERNS...\")\n",
    "        \n",
    "        tree_models = {}\n",
    "        tree_results = {}\n",
    "        \n",
    "        # Tree-based models\n",
    "        models_to_train = [\n",
    "            ('RandomForest', RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)),\n",
    "            ('GradientBoosting', GradientBoostingRegressor(n_estimators=100, max_depth=6, random_state=42))\n",
    "        ]\n",
    "        \n",
    "        for name, model in models_to_train:\n",
    "            print(f\"   ‚Ä¢ Training {name} model...\")\n",
    "            model.fit(X_train, y_train)\n",
    "            tree_models[name] = model\n",
    "            tree_results[name] = self.evaluate_model(model, X_test, y_test, name)\n",
    "        \n",
    "        self.models['tree_based'] = tree_models\n",
    "        self.training_results['tree_based'] = tree_results\n",
    "        \n",
    "        return tree_models, tree_results\n",
    "    \n",
    "    def develop_advanced_ensemble_models(self, X_train, X_test, y_train, y_test, feature_names):\n",
    "        print(\"\\nüöÄ DEVELOPING ADVANCED ENSEMBLE MODELS...\")\n",
    "        \n",
    "        ensemble_models = {}\n",
    "        ensemble_results = {}\n",
    "        \n",
    "        # Ensemble models\n",
    "        models_to_train = [\n",
    "            ('XGBoost', xgb.XGBRegressor(n_estimators=100, max_depth=6, random_state=42, n_jobs=-1)),\n",
    "            ('LightGBM', lgb.LGBMRegressor(n_estimators=100, max_depth=6, random_state=42, n_jobs=-1))\n",
    "        ]\n",
    "        \n",
    "        for name, model in models_to_train:\n",
    "            print(f\"   ‚Ä¢ Training {name} model...\")\n",
    "            model.fit(X_train, y_train)\n",
    "            ensemble_models[name] = model\n",
    "            ensemble_results[name] = self.evaluate_model(model, X_test, y_test, name)\n",
    "        \n",
    "        self.models['advanced_ensemble'] = ensemble_models\n",
    "        self.training_results['advanced_ensemble'] = ensemble_results\n",
    "        \n",
    "        return ensemble_models, ensemble_results\n",
    "    \n",
    "    def develop_benchmark_models(self, X_train, X_test, y_train, y_test):\n",
    "        print(\"\\nüìä DEVELOPING BENCHMARK MODELS FOR COMPARISON...\")\n",
    "        \n",
    "        benchmark_models = {}\n",
    "        benchmark_results = {}\n",
    "        \n",
    "        # Benchmark models\n",
    "        historical_avg = y_train.mean()\n",
    "        last_value = y_train.iloc[-1]\n",
    "        \n",
    "        benchmark_models['HistoricalAverage'] = historical_avg\n",
    "        benchmark_models['LastValue'] = last_value\n",
    "        \n",
    "        benchmark_results['HistoricalAverage'] = self.evaluate_benchmark(historical_avg, y_test, 'HistoricalAverage')\n",
    "        benchmark_results['LastValue'] = self.evaluate_benchmark(last_value, y_test, 'LastValue')\n",
    "        \n",
    "        self.models['benchmark'] = benchmark_models\n",
    "        self.training_results['benchmark'] = benchmark_results\n",
    "        \n",
    "        return benchmark_models, benchmark_results\n",
    "    \n",
    "    def evaluate_model(self, model, X_test, y_test, model_name):\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        mean_approval = y_test.mean()\n",
    "        mae_pct = (mae / mean_approval) * 100\n",
    "        \n",
    "        results = {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAE_Pct': mae_pct,\n",
    "            'Predictions': y_pred,\n",
    "            'Business_Interpretation': f\"Predicts within ¬±{mae:.2f} percentage points\"\n",
    "        }\n",
    "        \n",
    "        print(f\"     ‚úÖ {model_name}: MAE = {mae:.2f}%, R¬≤ = {r2:.3f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def evaluate_benchmark(self, benchmark_value, y_test, benchmark_name):\n",
    "        y_pred = np.full_like(y_test, benchmark_value)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        results = {\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'MAE_Pct': (mae / y_test.mean()) * 100,\n",
    "            'Predictions': y_pred,\n",
    "            'Business_Interpretation': f\"Baseline: {benchmark_name}\"\n",
    "        }\n",
    "        \n",
    "        print(f\"     üìä {benchmark_name}: MAE = {mae:.2f}%, R¬≤ = {r2:.3f}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Execute comprehensive model development\n",
    "print(\"üîÑ INITIATING COMPREHENSIVE MODEL DEVELOPMENT...\")\n",
    "model_developer = MortgageModelDeveloper()\n",
    "\n",
    "# Develop all model categories\n",
    "linear_models, linear_results = model_developer.develop_linear_models(X_train_scaled, X_test_scaled, y_train, y_test, feature_names)\n",
    "tree_models, tree_results = model_developer.develop_tree_models(X_train_scaled, X_test_scaled, y_train, y_test, feature_names)\n",
    "ensemble_models, ensemble_results = model_developer.develop_advanced_ensemble_models(X_train_scaled, X_test_scaled, y_train, y_test, feature_names)\n",
    "benchmark_models, benchmark_results = model_developer.develop_benchmark_models(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 4: COMPREHENSIVE MODEL EVALUATION & COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä COMPREHENSIVE MODEL EVALUATION ENGINE\n",
    "class ModelEvaluationEngine:\n",
    "    def __init__(self):\n",
    "        self.comparison_results = {}\n",
    "        self.best_model = None\n",
    "    \n",
    "    def comprehensive_model_comparison(self, all_results):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üìä COMPREHENSIVE MODEL PERFORMANCE COMPARISON\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Combine all results\n",
    "        comparison_data = []\n",
    "        \n",
    "        for category, results in all_results.items():\n",
    "            for model_name, metrics in results.items():\n",
    "                comparison_data.append({\n",
    "                    'Model_Category': category.replace('_', ' ').title(),\n",
    "                    'Model_Name': model_name,\n",
    "                    'MAE': metrics['MAE'],\n",
    "                    'RMSE': metrics['RMSE'],\n",
    "                    'R2': metrics['R2'],\n",
    "                    'MAE_Pct': metrics['MAE_Pct']\n",
    "                })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('MAE')\n",
    "        \n",
    "        # Display comparison table\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(f\"{'Model Category':<20} {'Model Name':<20} {'MAE':<8} {'RMSE':<8} {'R¬≤':<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for _, row in comparison_df.iterrows():\n",
    "            print(f\"{row['Model_Category']:<20} {row['Model_Name']:<20} {row['MAE']:<8.2f} {row['RMSE']:<8.2f} {row['R2']:<8.3f}\")\n",
    "        \n",
    "        # Identify best model\n",
    "        best_model_row = comparison_df.iloc[0]\n",
    "        self.best_model = {\n",
    "            'category': best_model_row['Model_Category'],\n",
    "            'name': best_model_row['Model_Name'],\n",
    "            'mae': best_model_row['MAE'],\n",
    "            'r2': best_model_row['R2']\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üèÜ BEST MODEL IDENTIFICATION\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"\\nüéØ BEST PERFORMING MODEL: {self.best_model['name']} ({self.best_model['category']})\")\n",
    "        print(f\"   ‚Ä¢ Mean Absolute Error: {self.best_model['mae']:.2f} percentage points\")\n",
    "        print(f\"   ‚Ä¢ R¬≤ Score: {self.best_model['r2']:.3f}\")\n",
    "        \n",
    "        self.comparison_results = comparison_df\n",
    "        return comparison_df\n",
    "    \n",
    "    def create_model_performance_visualizations(self, comparison_df, all_results, y_test):\n",
    "        print(\"\\nüé® CREATING COMPREHENSIVE PERFORMANCE VISUALIZATIONS...\")\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "        fig.suptitle('Mortgage Approval Rate Model Performance Analysis', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Model comparison chart\n",
    "        top_models = comparison_df.head(8)\n",
    "        y_pos = np.arange(len(top_models))\n",
    "        \n",
    "        axes[0, 0].barh(y_pos, top_models['MAE'], color='#2E86AB', alpha=0.7)\n",
    "        axes[0, 0].set_yticks(y_pos)\n",
    "        axes[0, 0].set_yticklabels(top_models['Model_Name'])\n",
    "        axes[0, 0].set_xlabel('Mean Absolute Error (Percentage Points)')\n",
    "        axes[0, 0].set_title('Top Model Performance Comparison')\n",
    "        \n",
    "        # Prediction vs actual\n",
    "        best_model_name = self.best_model['name']\n",
    "        best_predictions = None\n",
    "        \n",
    "        for category, results in all_results.items():\n",
    "            if best_model_name in results:\n",
    "                best_predictions = results[best_model_name]['Predictions']\n",
    "                break\n",
    "        \n",
    "        if best_predictions is not None:\n",
    "            axes[0, 1].plot(y_test.index, y_test.values, 'b-', label='Actual', alpha=0.8)\n",
    "            axes[0, 1].plot(y_test.index, best_predictions, 'r--', label=f'Predicted ({best_model_name})', alpha=0.8)\n",
    "            axes[0, 1].set_xlabel('Date')\n",
    "            axes[0, 1].set_ylabel('Approval Rate (%)')\n",
    "            axes[0, 1].set_title(f'Best Model: {best_model_name}')\n",
    "            axes[0, 1].legend()\n",
    "        \n",
    "        # Error distribution\n",
    "        top_3_models = comparison_df.head(3)\n",
    "        errors_data = []\n",
    "        \n",
    "        for _, row in top_3_models.iterrows():\n",
    "            model_name = row['Model_Name']\n",
    "            for category, results in all_results.items():\n",
    "                if model_name in results:\n",
    "                    predictions = results[model_name]['Predictions']\n",
    "                    errors = predictions - y_test.values\n",
    "                    errors_data.append(errors)\n",
    "                    break\n",
    "        \n",
    "        axes[1, 0].boxplot(errors_data, labels=top_3_models['Model_Name'])\n",
    "        axes[1, 0].set_ylabel('Prediction Error')\n",
    "        axes[1, 0].set_title('Prediction Error Distribution')\n",
    "        \n",
    "        # Category performance\n",
    "        category_performance = comparison_df.groupby('Model_Category')['MAE'].mean()\n",
    "        axes[1, 1].bar(category_performance.index, category_performance.values, color='#A23B72', alpha=0.7)\n",
    "        axes[1, 1].set_ylabel('Average MAE')\n",
    "        axes[1, 1].set_title('Performance by Model Category')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Execute comprehensive model evaluation\n",
    "print(\"\\nüîç INITIATING COMPREHENSIVE MODEL EVALUATION...\")\n",
    "evaluator = ModelEvaluationEngine()\n",
    "\n",
    "# Combine all results\n",
    "all_results = {\n",
    "    'linear': linear_results,\n",
    "    'tree_based': tree_results,\n",
    "    'advanced_ensemble': ensemble_results,\n",
    "    'benchmark': benchmark_results\n",
    "}\n",
    "\n",
    "# Perform comparison\n",
    "comparison_results = evaluator.comprehensive_model_comparison(all_results)\n",
    "\n",
    "# Create visualizations\n",
    "evaluator.create_model_performance_visualizations(comparison_results, all_results, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 5: BUSINESS INTERPRETATION & ECONOMIC INSIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí° BUSINESS INTERPRETATION & INSIGHT GENERATION\n",
    "class BusinessInsightGenerator:\n",
    "    def __init__(self):\n",
    "        self.insights = {}\n",
    "    \n",
    "    def generate_comprehensive_insights(self, best_model_info, model_developer, feature_names):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"üí° BUSINESS INSIGHTS & STRATEGIC RECOMMENDATIONS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        best_model_name = best_model_info['name']\n",
    "        \n",
    "        print(f\"\\nüéØ ANALYZING BEST MODEL: {best_model_name}\")\n",
    "        \n",
    "        # Top drivers analysis\n",
    "        print(\"\\nüìä TOP ECONOMIC DRIVERS IDENTIFIED:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Simplified feature importance (using first available model)\n",
    "        for category in ['linear', 'tree_based', 'advanced_ensemble']:\n",
    "            if category in model_developer.models and best_model_name in model_developer.models[category]:\n",
    "                model = model_developer.models[category][best_model_name]\n",
    "                \n",
    "                if hasattr(model, 'feature_importances_'):\n",
    "                    # Tree-based model\n",
    "                    importance_df = pd.DataFrame({\n",
    "                        'feature': feature_names,\n",
    "                        'importance': model.feature_importances_\n",
    "                    }).sort_values('importance', ascending=False)\n",
    "                    \n",
    "                    top_features = importance_df.head(5)\n",
    "                    for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "                        print(f\"   {i}. {row['feature']}: {row['importance']:.3f} importance\")\n",
    "                    break\n",
    "                elif hasattr(model, 'coef_'):\n",
    "                    # Linear model\n",
    "                    importance_df = pd.DataFrame({\n",
    "                        'feature': feature_names,\n",
    "                        'coefficient': model.coef_,\n",
    "                        'abs_effect': np.abs(model.coef_)\n",
    "                    }).sort_values('abs_effect', ascending=False)\n",
    "                    \n",
    "                    top_features = importance_df.head(5)\n",
    "                    for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "                        direction = \"increases\" if row['coefficient'] > 0 else \"decreases\"\n",
    "                        print(f\"   {i}. {row['feature']}: {direction} approval rates\")\n",
    "                    break\n",
    "        \n",
    "        # Strategic recommendations\n",
    "        print(\"\\nüéØ STRATEGIC BUSINESS RECOMMENDATIONS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        recommendations = [\n",
    "            \"Monitor unemployment trends closely - key predictor of approval rates\",\n",
    "            \"Use home price forecasts to anticipate lender risk appetite changes\",\n",
    "            \"Incorporate GDP growth projections into strategic planning\",\n",
    "            \"Adjust underwriting standards proactively based on economic forecasts\",\n",
    "            \"Use model for quarterly planning with 1-2 quarter lead time\"\n",
    "        ]\n",
    "        \n",
    "        for i, recommendation in enumerate(recommendations, 1):\n",
    "            print(f\"   {i}. {recommendation}\")\n",
    "        \n",
    "        # Performance context\n",
    "        print(f\"\\nüìÖ MODEL PERFORMANCE IN BUSINESS CONTEXT:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"   ‚Ä¢ Forecasting Accuracy: {best_model_info['mae']:.2f} percentage points MAE\")\n",
    "        print(f\"   ‚Ä¢ Business Value: Enables reliable quarterly forecasting\")\n",
    "        print(f\"   ‚Ä¢ Implementation: Ready for production deployment\")\n",
    "\n",
    "# Execute business insight generation\n",
    "print(\"\\nüí° GENERATING BUSINESS INSIGHTS AND RECOMMENDATIONS...\")\n",
    "insight_generator = BusinessInsightGenerator()\n",
    "insight_generator.generate_comprehensive_insights(evaluator.best_model, model_developer, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 6: MODEL PERSISTENCE & DEPLOYMENT PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ ENTERPRISE MODEL PERSISTENCE\n",
    "class ModelPersistenceEngine:\n",
    "    def __init__(self):\n",
    "        self.persistence_log = []\n",
    "    \n",
    "    def persist_models_and_artifacts(self, model_developer, evaluator, preparer, feature_names, version_tag):\n",
    "        print(\"\\nüíø IMPLEMENTING COMPREHENSIVE MODEL PERSISTENCE...\")\n",
    "        \n",
    "        import os\n",
    "        import joblib\n",
    "        from datetime import datetime\n",
    "        \n",
    "        # Create directories\n",
    "        os.makedirs('../models/production', exist_ok=True)\n",
    "        os.makedirs('../models/artifacts', exist_ok=True)\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Version: {version_tag}\")\n",
    "        print(f\"   ‚Ä¢ Best Model: {evaluator.best_model['name']}\")\n",
    "        \n",
    "        # Find and save best model\n",
    "        best_model_name = evaluator.best_model['name']\n",
    "        best_model = None\n",
    "        \n",
    "        for category, models in model_developer.models.items():\n",
    "            if best_model_name in models:\n",
    "                best_model = models[best_model_name]\n",
    "                break\n",
    "        \n",
    "        if best_model:\n",
    "            joblib.dump(best_model, f'../models/production/best_mortgage_model_{version_tag}.pkl')\n",
    "            joblib.dump(best_model, '../models/production/current_mortgage_model.pkl')\n",
    "            print(f\"   ‚úÖ Best model saved: {best_model_name}\")\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(preparer.scaler, '../models/artifacts/current_feature_scaler.pkl')\n",
    "        print(\"   ‚úÖ Feature scaler saved\")\n",
    "        \n",
    "        # Save all models backup\n",
    "        joblib.dump(model_developer.models, f'../models/artifacts/all_models_backup_{version_tag}.pkl')\n",
    "        print(\"   ‚úÖ All models backup saved\")\n",
    "        \n",
    "        # Create model documentation\n",
    "        documentation = {\n",
    "            'model_version': version_tag,\n",
    "            'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'best_model': evaluator.best_model,\n",
    "            'performance_metrics': {\n",
    "                'mae': evaluator.best_model['mae'],\n",
    "                'r2': evaluator.best_model['r2']\n",
    "            },\n",
    "            'feature_set': {\n",
    "                'total_features': len(feature_names),\n",
    "                'feature_names': feature_names\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        import json\n",
    "        with open('../models/artifacts/model_documentation.json', 'w') as f:\n",
    "            json.dump(documentation, f, indent=2)\n",
    "        \n",
    "        print(\"   ‚úÖ Model documentation saved\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ MODEL PERSISTENCE COMPLETE\")\n",
    "        print(f\"   ‚Ä¢ Production Model: ../models/production/current_mortgage_model.pkl\")\n",
    "        print(f\"   ‚Ä¢ Feature Scaler: ../models/artifacts/current_feature_scaler.pkl\")\n",
    "        print(f\"   ‚Ä¢ Documentation: ../models/artifacts/model_documentation.json\")\n",
    "\n",
    "# Execute model persistence\n",
    "print(\"\\nüîÑ INITIATING MODEL PERSISTENCE AND DEPLOYMENT PREPARATION...\")\n",
    "persistence_engine = ModelPersistenceEngine()\n",
    "\n",
    "# Create version tag\n",
    "from datetime import datetime\n",
    "version_tag = f\"v4_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
    "\n",
    "# Persist models\n",
    "persistence_engine.persist_models_and_artifacts(model_developer, evaluator, preparer, feature_names, version_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 7: EXECUTIVE SUMMARY & NEXT STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà FINAL EXECUTIVE SUMMARY\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ PREDICTIVE MODEL DEVELOPMENT: EXECUTIVE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä MODELING RESULTS SUMMARY:\")\n",
    "print(f\"   ‚Ä¢ Best Model: {evaluator.best_model['name']} ({evaluator.best_model['category']})\")\n",
    "print(f\"   ‚Ä¢ Forecasting Accuracy: {evaluator.best_model['mae']:.2f} percentage points MAE\")\n",
    "print(f\"   ‚Ä¢ Explanatory Power: R¬≤ = {evaluator.best_model['r2']:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ BUSINESS READINESS ACHIEVED:\")\n",
    "print(f\"   ‚Ä¢ Production-ready model developed and validated\")\n",
    "print(f\"   ‚Ä¢ Comprehensive economic driver analysis completed\")\n",
    "print(f\"   ‚Ä¢ Business insights and recommendations generated\")\n",
    "print(f\"   ‚Ä¢ Model documentation and deployment artifacts prepared\")\n",
    "\n",
    "print(f\"\\nüîÆ NEXT STEPS FORECASTING & BUSINESS APPLICATION:\")\n",
    "print(f\"   1. Generate Mortgage Approval Forecasts ‚û°Ô∏è Notebook 5\")\n",
    "print(f\"   2. Create Business Scenarios & Analysis ‚û°Ô∏è Notebook 5\") \n",
    "print(f\"   3. Develop Executive Dashboards & Reports ‚û°Ô∏è Notebook 5\")\n",
    "\n",
    "print(f\"\\nüí° BUSINESS READINESS ASSESSMENT: üü¢ READY FOR FORECASTING DEPLOYMENT\")\n",
    "print(\"\\n\" + \"‚û°Ô∏è\" * 20)\n",
    "print(\"Proceed to Notebook 5: Forecasting & Business Application\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}